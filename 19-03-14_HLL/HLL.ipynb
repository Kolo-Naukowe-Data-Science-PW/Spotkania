{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytmy szacujące wyniki zapytań COUNT DISTINCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W referacie wykonam krótki przegląd algorytmów rozwiązywania problemu liczenia unikalnych elementów złączalnych multizbiorów (COUNT DISTINCT). Opowiem o jednym z pierwszych algorytmów probabilistycznych związanych z problemem - algorytmie Flajoleta-Martina [1] i wyjaśnię wady oryginalnej wersji algorytmu. Oprócz tego przedstawię probabilistyczną metodę odzyskiwania liczności zbioru unikalnych elementów. Następnie opowiem o modyfikacjach poprawiających dokładność szacowania liczby unikalnych elementów i wprowadzę algorytm HyperLogLog [2]. Na końcu pokażę przykład dostępnej implementacji - PostgresHLL.\n",
    "#  \n",
    "#  \n",
    "#### Bibliografia\n",
    "\n",
    "[1] Flajolet, Philippe; Martin, G. Nigel (1985). \"Probabilistic counting algorithms for data base applications\".Journal of Computer and System Sciences. 31 (2): 182–209. doi:10.1016/0022-0000(85)90041-8\n",
    "\n",
    "[2] Flajolet, Philippe; Fusy, Éric; Gandouet, Olivier; Meunier, Frédéric (2007). \"Hyperloglog: The analysis of a near-optimal cardinality estimation algorithm\". Discrete Mathematics and Theoretical Computer Science proceedings. Nancy, France. AH: 127–146."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "## Sformułowanie problemu\n",
    "\n",
    "**Wejście:** $M$ - multizbiór\n",
    "\n",
    "**Wyjście:** $n$ - liczba unikalnych elementów multizbioru $M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "## Naiwne rozwiązanie\n",
    "\n",
    "* Inicjalizujemy pusty zbiór $U$\n",
    "* Przechodzimy po wszystkich elementach multizbioru $M$ i dodajemy je do zbioru $U$\n",
    "* Zwracamy liczność zbioru $U$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unique_elements = set()\n",
    "for element in M:\n",
    "    unique_elements.add(element)\n",
    "n = len(unique_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kilka słów o złożoności\n",
    "#  \n",
    "Złożoności powyższego algorytmu wyglądają następująco:\n",
    "\n",
    "* obliczeniowa - $O(|M|)$\n",
    "* pamięciowa - $O(n)$\n",
    "\n",
    "Przez naturę problemu jesteśmy zmuszeni obejrzeć każdy element multizbioru $M$ w celu ustalenia czy dany element pojawił się już wcześniej. Stąd wiemy,że złożoność obliczeniowa jaką uzyskaliśmy jest optymalna. Wadą tego rozwiązania jest natomiast złożoność pamięciowa, która jest zależna od liczby unikalnych elementów multizbioru $M$. W przypadku gdy ta liczba jest bardzo duża, powyższy algorytm staje się niewydajny. Rozważmy zatem następującą alternatywę."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm Flajoleta-Martina\n",
    "\n",
    "$U:=$ zbiór unikalnych wartości multizbioru $M$\n",
    "\n",
    "Wybierzmy funkcję hashującą $hash$ taką, że $hash(U)$ jest zmienną losową o rozkładzie jednostajnym dyskretnym o wartościach w zbiorze $\\{0,1,\\dots,2^L-1\\}$, przy czym możemy przyjąć $L=log_2|M|+10$. Wartości funkcji $hash$ możemy interpretować jako ciąg binarny długości $L$ reprezentujący odpowiadającą mu liczbę. (Przykładowo jeżeli $L = 8$, to ciąg binarny $\\langle 00001000 \\rangle_2$ odpowiada liczbie $8$)\n",
    "\n",
    "\n",
    "Niech $x \\in M$. Wtedy:\n",
    "\n",
    "$$y = hash(x)$$\n",
    "\n",
    "$bit(y,k)$ - $k$-ty bit reprezentacji binarnej $y$.\n",
    "\n",
    "$$y = \\sum_{k\\geq0}bit(y,k)2^k$$\n",
    "\n",
    "$\\rho(y)$ - pozycja najmniej znaczącego niezerowego bitu reprezentacji binarnej $y$.\n",
    "\n",
    "**Przykłady:**\n",
    "* $\\rho(5)=0$, ponieważ $5=\\langle 0101 \\rangle_2$\n",
    "* $\\rho(6)=1$, ponieważ $6=\\langle 0110 \\rangle_2$\n",
    "* $\\rho(8)=3$, ponieważ $8=\\langle 1000 \\rangle_2$\n",
    "\n",
    "**Uwaga:**\n",
    "Ponieważ $\\rho(0)$ nie ma według powyższej definicji określonej wartości, ustalmy $\\rho(0)=0$\n",
    "\n",
    "Dla przejrzystosci obliczeń oznaczmy $H:=hash(U)$ przy czym pamiętamy, że $H$ jest zmienną losową o rozkładzie jednostajnym dyskretnym. Stąd wynika, że \n",
    "\n",
    "$$P(H=\\langle\\dots10^k\\rangle_2)=2^{-k-1}$$\n",
    "\n",
    "Powyższy napis oznacza prawdopodobieństwo, że ciąg binarny reprezentujący wartość zmiennej losowej $H$ ma na końcu $k$ zer i jedynkę na $L-k-1$ miejscu. \n",
    "\n",
    "Przejdźmy zatem do pierwszej częsci algorytmu:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bitmap = [0]*L\n",
    "for x in M:\n",
    "    index = 𝜌(hash(x))\n",
    "    if bitmap[index]==0:\n",
    "        bitmap[index]=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po przejściu przez multizbiór $M$ otrzymujemy tablicę $bitmap$ długości $L$ o wartościach $0$ lub $1$.\n",
    "\n",
    "Zastanówmy się nad wyrażeniem\n",
    "$$P(\\rho(H) = k)$$\n",
    "Jest to prawdopodobieństwo odwołania się do k-tej komórki tablicy. Okazuje się, że jest to nic innego jak zdefiniowane przez nas wcześniej\n",
    "$$P(H=\\langle\\dots10^k\\rangle_2)$$\n",
    "Zatem wiemy, że w przybliżeniu $\\frac{n}{2}$ elementów $U$ odwoływało się do $bitmap[0]$, $\\frac{n}{4}$ elementów $U$ odwoływało się do $bitmap[1]$ itd. Stąd możemy wyciągnąc następujące wnioski:\n",
    "\n",
    "* $bitmap[j]=1$, gdy $j \\ll log_2n$\n",
    "\n",
    "* $bitmap[j] \\in \\{0,1\\}$ gdy $j \\approx log_2n$\n",
    "\n",
    "* $bitmap[j]=0$ gdy $j \\gg log_2n$\n",
    "\n",
    "Niech $R$ oznacza pozycję pierwszego zera licząc od lewej.\n",
    "\n",
    "Algorytm Flajoleta-Martina mówi nam, że:\n",
    "\n",
    "$$n\\approx\\frac{2^R}{\\phi}, \\phi=0.77351\\dots$$\n",
    "\n",
    "**Uwaga:**\n",
    "W oryginalnej pracy opisującej algorytm pojawiają się dwie równości, których dowody są zbyt długie w stosunku do pojemności tego referatu\n",
    "\n",
    "$$\\mathbb{E}(R)=log_2(\\phi n)$$\n",
    "\n",
    "$$\\sigma(R)=1.12\\dots$$\n",
    "\n",
    "Z powyższych równości wynika, że szacowanie liczby unikalnych elementów multizbioru może różnić się od rzeczywistej wartości o rzędy wielkości. W celu zniwelowania tego efektu można wykonać powyższy eksperyment $k$ razy, za każdym razem korzystając z innej funkcji hashującej i policzyć średnią z oszacowanych wartości. Wadą tego rozwiązania jest niska odporność na wartości odstające, które bez wątpienia będą się pojawiać - oszacowania różnią się przecież o całe rzędy wielkości. Innym sposobem, jest wybranie mediany ze zwróconych wartości. W tym wypadku wadą będzie ograniczony zakres możliwych wartości, ograniczony do przeskalowanych potęg dwójki. W praktyce wykonuje się $k\\cdot l$ eksperymentów, z różną funkcją hashującą w każdym. Wtedy dla każdej wartości $i=1,\\dots,k$ wykonujemy $l$ eksperymentów, z których wyciągamy medianę wyników, a następnie liczymy średnią median. W ten sposób jesteśmy w stanie znacząco poprawić oszacowanie, kosztem zwiększonej złożoności obliczeniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja algorytmu Flajoleta-Martina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from HLL import HyperLogLog\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit(y, k):\n",
    "    return bin(y)[-(k+1)]\n",
    "def rho(y):\n",
    "    if y==0:\n",
    "        return 0\n",
    "    for i, b in enumerate(bin(y)[:1:-1]):\n",
    "        if b == '1':\n",
    "            return i\n",
    "def find_R(bitmap):\n",
    "    for i, b in enumerate(bitmap):\n",
    "        if b == '0':\n",
    "            return i\n",
    "    return len(bitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = {f'word{i}' for i in range(256000)}\n",
    "unique_words_subsets = {k:{f'word{i}' for i in range(k*16000,(k+1)*16000)} for k in range(16)}\n",
    "multisets = {k: np.random.choice(list(unique_words.difference(unique_words_subsets[k])), size=1500000) for k in range(16)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111111111111111111000000000000\n",
      "111111111111111110100000000000\n",
      "111111111111111001000000000000\n",
      "111111111111111111100000000000\n",
      "111111111111111111010000000000\n",
      "111111111111111110110000000000\n",
      "111111111111111101010000000000\n",
      "111111111111111111100000000000\n",
      "111111111111111111100000000000\n",
      "111111111111111001000000000000\n",
      "111111111111111100100000000000\n",
      "111111111111111111010000100000\n",
      "111111111111111111000000000000\n",
      "111111111111111101000000000000\n",
      "111111111111111111110000000000\n",
      "111111111111111110100000000000\n",
      "111111111111111100010000000000\n",
      "111111111111111101100100000000\n",
      "111111111111111111010000000000\n",
      "111111111111111110100000000000\n",
      "111111111111111101001000000000\n",
      "111111111111111111000000000000\n",
      "111111111111111110100000000000\n",
      "111111111111111111001000000000\n",
      "111111111111111110000000000000\n",
      "237231.32215485256\n"
     ]
    }
   ],
   "source": [
    "M = multisets[0]\n",
    "L = int(np.log2(len(M)))+10\n",
    "phi=0.77351\n",
    "k = 5\n",
    "l = 5\n",
    "medians=[]\n",
    "for a, seed1 in enumerate(np.random.randint(0, 256, k)):\n",
    "    results=[]\n",
    "    for b, seed2 in enumerate(np.random.randint(0, 256, l)):\n",
    "        bitmap=['0']*L\n",
    "        for record in M:\n",
    "            index = rho(abs(hash(f'{record}{seed1}{seed2}'))%2**L)\n",
    "            if bitmap[index]=='0':\n",
    "                bitmap[index]='1'\n",
    "        str_bitmap = reduce(lambda x, y: x+y, bitmap)\n",
    "        print(f'{str_bitmap}\\n', end='\\r', flush=True)\n",
    "        results.append(2**find_R(str_bitmap)/phi)\n",
    "        print(f'{a*k+b+1}/{k*l}', end='\\r', flush=True)\n",
    "    medians.append(np.median(results))\n",
    "print(np.mean(medians))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperLogLog\n",
    "\n",
    "Pochodzący z 2007 roku algorytm, współautorstwa Flajoleta, wprowadza następujące usprawnienia:\n",
    "\n",
    "1. Zwiększona precyzja oszacowania liczby unikalnych elementów, przy złożoności obliczeniowej $O(|M|)$ - brak potrzeby wielokrotnego powtarzania eksperymentów\n",
    "2. Stworzenie struktury danych HLL będącej reprezentacją zbioru unikalnych elementów multizbioru $M$, która udostępnia metody\n",
    "    1. add\n",
    "    2. count\n",
    "    3. merge\n",
    "    \n",
    "#  \n",
    "#  \n",
    "### Idea algorytmu\n",
    "W uwadze do algorytmu Flajoleta-Martina powiedzieliśmy, że wysoka wariancja $R$ wpływa na dużą niedokładność oszacowania liczby unikalnych elementów multizbioru $M$. W celu pozbycia się tego problemu, wykonywaliśmy wiele eksperymentów i liczyliśmy pewien agregat ich wyników. Algorytm HyperLogLog działa według podobnej idei. Zamiast wykonywać $m$ eksperymentów, tworzymy rejestry $B_i, i=0,\\dots,m-1$ przechowujące najwyższą wartość $\\rho$ z algorytmu Flajoleta-Martina dla danej grupy elementów. Niech $m$ będzie postaci $m=2^k$.\n",
    "\n",
    "$hash(x)$, $y$, $\\rho(y)$ oznaczają to samo co w algorytmie Flajoleta-Martina\n",
    "\n",
    "Inicjalizujemy pustą strukturę HLL o $m$ rejestrach (każdy rejestr jest wypełniony zerami). Dla każdego rekordu z multizbioru $M$ obliczamy wartość jego hasha. Bity od $0$ do $k-1$ kodują indeks $j$ rejestru, w którym zapiszemy wystąpienie danego rekordu. Na podstawie pozostałych bitów liczymy $\\rho$ i wstawiamy w dane miejsce jedynkę. Inaczej tę procedurę możemy zapisać jako:\n",
    "***\n",
    "$$j = y\\ mod\\ m$$\n",
    "***\n",
    "$$w = y - j$$\n",
    "***\n",
    "$$B_j=max\\{B_j,\\rho(w)\\}$$\n",
    "\n",
    "Liczność zbioru unikalnych elementów szacowana jest za pomocą średniej harmonicznej. Wiemy, że w każdym z rejestrów powinno być zapisanych około $\\frac{n}{m}$ elementów.\n",
    "$$ Z = \\frac{1}{\\sum_{i=0}^{m-1}2^{-B_i}}$$\n",
    "\n",
    "$$\\frac{n}{m} \\approx mZ$$\n",
    "\n",
    "Biorąc pod uwagę konflikty hashowania, możemy wyliczyć stałą szacowania $\\alpha_m$. Wtedy\n",
    "\n",
    "$$n = \\alpha_m m^2 Z$$\n",
    "\n",
    "$$\\alpha_m = \\frac{1}{m \\int_0^\\infty(log_2(\\frac{2+u}{1+u}))^m du}$$\n",
    "\n",
    "Obliczenie $\\alpha_m$ nie jest najprostszą czynnością, dlatego wykorzystuje się poniższe oszacowanie:\n",
    "\n",
    "$$\\alpha_m = \n",
    "\\begin{cases}\n",
    "0.673, m=16\\\\\n",
    "0.697, m=32\\\\\n",
    "0.709, m=64\\\\\n",
    "\\frac{0.7213}{1+\\frac{1.079}{m}}, m \\geq 128\n",
    "\\end{cases}$$\n",
    "\n",
    "## Merge\n",
    "\n",
    "Niech $hll_1, hll_2$ będą strukturami HLL, obie mają m rejestrów, a $j$-ty rejestr strutury $hll_i$ oznaczmy jako $hll_{i,j}$. Wtedy\n",
    "\n",
    "$$union(hll_1, hll_2)[j] = max\\{hll_{1,j},hll_{2,j}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 16\n",
    "hll1 = HyperLogLog(b)\n",
    "hll2 = HyperLogLog(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = multisets[0]\n",
    "M1 = multisets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in M0:\n",
    "    hll1.add(record)\n",
    "    \n",
    "for record in M1:\n",
    "    hll2.add(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255941"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(M0).union(set(M1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239534"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(M0).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239571"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(M1).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240681.13362848014"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hll1.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240529.29328457054"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hll2.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256336.23671754944"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hll1.merge(hll2)\n",
    "hll1.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = hll1.cardinality() + hll2.cardinality() - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
