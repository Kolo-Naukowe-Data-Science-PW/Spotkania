{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #import biblioteki do obliczeń na macierzach (i tensorach)\n",
    "import pandas as pd #import biblioteki do przetwarzania ramek z danymi\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data,names_of_x,name_of_y,number_of_parts=5,seed=123):\n",
    "    data = data.sample(data.shape[0],random_state=seed) #losowa zmiana kolejności wierszy\n",
    "    dataX = np.array(data.loc[:,names_of_x]) #wybranie odpowiednich kolumn\n",
    "    dataX = np.c_[np.ones(dataX.shape[0]),dataX] #dodanie kolumny jedynek\n",
    "    dataY = np.array(data.loc[:,name_of_y]) #wektor wartości\n",
    "    \n",
    "    #listy z danymi i wartościami cen\n",
    "    trainX = [0]*number_of_parts\n",
    "    trainY = [0]*number_of_parts\n",
    "    cvX = [0]*number_of_parts\n",
    "    cvY = [0]*number_of_parts\n",
    "    for i in range(number_of_parts):\n",
    "        trainX[i] = np.r_[dataX[0:int(data.shape[0]*i/number_of_parts),:],\n",
    "                      dataX[int(data.shape[0]*(i+1)/number_of_parts):data.shape[0],:]]\n",
    "        trainY[i] = np.r_[dataY[0:int(data.shape[0]*i/number_of_parts)],\n",
    "                      dataY[int(data.shape[0]*(i+1)/number_of_parts):data.shape[0]]]\n",
    "        cvX[i] = dataX[int(data.shape[0]*i/number_of_parts):int(data.shape[0]*(i+1)/number_of_parts),:]\n",
    "        cvY[i] = dataY[int(data.shape[0]*i/number_of_parts):int(data.shape[0]*(i+1)/number_of_parts)]\n",
    "    return(trainX, trainY, cvX, cvY)\n",
    "\n",
    "def square_mean(X, Y, model):\n",
    "    return np.mean((X @ model.transpose() - Y) **2) ** (1/2)\n",
    "\n",
    "def linear_regression(trainX, trainY, cvX, cvY):\n",
    "    model = np.linalg.inv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "    return square_mean(cvX,cvY,model)\n",
    "\n",
    "def training(trainX, trainY, cvX, cvY, number_of_parts=5):\n",
    "    error = 0\n",
    "    for i in range(len(trainX)):\n",
    "        error += linear_regression(trainX[i], trainY[i], cvX[i], cvY[i])\n",
    "    return error/number_of_parts\n",
    "\n",
    "def mean_error(data,names_of_x,name_of_y,number_of_parts=5,seed=123,number_of_repeats=100):\n",
    "    error = 0\n",
    "    for i in range(number_of_repeats):\n",
    "        (trainX, trainY, cvX, cvY) = data_processing(train,names_of_x,name_of_y,number_of_parts,seed+i)\n",
    "        error += training(trainX, trainY, cvX, cvY)\n",
    "    return error/number_of_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('train.csv')\n",
    "#mean_error(train,('LotArea'),'SalePrice')\n",
    "def training2(trainX, trainY, cvX, cvY, x_names, number_of_parts=5):\n",
    "    error = 0\n",
    "    for i in range(len(trainX)):\n",
    "        error += linear_regression(trainX[i][:,x_names], trainY[i], cvX[i][:,x_names], cvY[i])\n",
    "    return error/number_of_parts\n",
    "\n",
    "def find_features(data,names_of_x,name_of_y,number_of_parts=5,seed=123,number_of_repeats=100):\n",
    "    if type(names_of_x)==str: m = 1\n",
    "    else: m = len(names_of_x)\n",
    "    errors = [0]*2**m\n",
    "    for i in range(number_of_repeats):\n",
    "        (trainX, trainY, cvX, cvY) = data_processing(train,names_of_x,name_of_y,number_of_parts,seed+i)\n",
    "        for j in range(1,2**m):\n",
    "            x_indices = [] #which names we use\n",
    "            true_false_list = ('{0:0'+str(m)+'b}').format(j) #the bollean string which names we should add to x_indices\n",
    "            for k in range(m):\n",
    "                if true_false_list[k] == '1': x_indices.append(k)\n",
    "            errors[j] += training2(trainX, trainY, cvX, cvY, x_indices, number_of_parts)/number_of_repeats\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_division(dataX,dataY,number_of_parts=5):\n",
    "    trainX = [0]*number_of_parts\n",
    "    trainY = [0]*number_of_parts\n",
    "    cvX = [0]*number_of_parts\n",
    "    cvY = [0]*number_of_parts\n",
    "    for i in range(number_of_parts):\n",
    "        trainX[i] = np.r_[dataX[0:int(data.shape[0]*i/number_of_parts),:],\n",
    "                      dataX[int(data.shape[0]*(i+1)/number_of_parts):data.shape[0],:]]\n",
    "        trainY[i] = np.r_[dataY[0:int(data.shape[0]*i/number_of_parts)],\n",
    "                      dataY[int(data.shape[0]*(i+1)/number_of_parts):data.shape[0]]]\n",
    "        cvX[i] = dataX[int(data.shape[0]*i/number_of_parts):int(data.shape[0]*(i+1)/number_of_parts),:]\n",
    "        cvY[i] = dataY[int(data.shape[0]*i/number_of_parts):int(data.shape[0]*(i+1)/number_of_parts)]\n",
    "    return(trainX, trainY, cvX, cvY)\n",
    "\n",
    "def training3(trainX, trainY, cvX, cvY, column_to_throw, number_of_parts=5):\n",
    "    error = 0\n",
    "    for i in range(len(trainX)):\n",
    "        error += linear_regression(np.delete(trainX[i],column_to_throw,1), trainY[i], np.delete(cvX[i],column_to_throw,1), cvY[i])\n",
    "    return error/number_of_parts\n",
    "\n",
    "def SBS(dataX,dataY,depth,number_of_parts=5):\n",
    "    m = dataX.shape[1]\n",
    "    (trainX, trainY, cvX, cvY) = CV_division(dataX,dataY,number_of_parts)\n",
    "    error = 0\n",
    "    for i in range(m-depth):\n",
    "        cur_error = np.inf\n",
    "        smallest_error = np.inf\n",
    "        column_to_throw = 0\n",
    "        for j in range(m-i):\n",
    "            cur_error = training3(trainX, trainY, cvX, cvY, j)\n",
    "            if cur_error<smallest_error:\n",
    "                smallest_error = cur_error\n",
    "                column_to_throw = j\n",
    "        for j in range(number_of_parts):\n",
    "            trainX[i] = np.delete(trainX[i],column_to_throw,1)\n",
    "            cvX = np.delete(cvX[i],column_to_throw,1)\n",
    "        error = smallest_error\n",
    "    return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 52891.001562095444,\n",
       " 56275.450579223514,\n",
       " 48290.429637995716,\n",
       " 77849.91762816977,\n",
       " 48747.5321111652,\n",
       " 55967.27768341839,\n",
       " 42977.34910715674,\n",
       " 136815.42328590088,\n",
       " 51747.88679175552,\n",
       " 55923.08341716125,\n",
       " 47959.25649752419,\n",
       " 75734.41933906451,\n",
       " 46922.19893994372,\n",
       " 55706.106397074676,\n",
       " 42189.5406177284,\n",
       " 79270.14059498113,\n",
       " 48555.35032731712,\n",
       " 56141.15998489189,\n",
       " 42585.6693225605,\n",
       " 67570.08884419451,\n",
       " 48115.36138744172,\n",
       " 46822.122279740615,\n",
       " 40837.14531846107,\n",
       " 77069.54600452716,\n",
       " 46688.18024092561,\n",
       " 55869.53615871734,\n",
       " 41772.69228697753,\n",
       " 65030.81113718823,\n",
       " 46110.10900623327,\n",
       " 46289.14603044514,\n",
       " 39968.121718407296]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "errors = find_features(train,('LotArea','YearBuilt','GrLivArea','OverallQual','TotalBsmtSF'),'SalePrice')\n",
    "pd.read_csv('train.csv').sort_values(by='SalePrice',ascending=False).reset_index(drop=True).columns\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przydzielone zadania\n",
    "- Wojtek Kretowicz - implementation using scikit learn\n",
    "- Karol Pysiak - remove Nas (must have), one-hot-encoding for strings (colud have)\n",
    "- Tomek Makowski - class based on the function here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
