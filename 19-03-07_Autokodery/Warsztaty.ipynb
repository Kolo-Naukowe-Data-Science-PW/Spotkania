{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oICQJmpggapN"
   },
   "source": [
    "# Autokodery\n",
    "### Jakub Janaszkiewicz – Warsztaty KNDS MiNI – 07.03.2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99yQbmsPgqrc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "%matplotlib inline\n",
    "mpl.rcParams['grid.color'] = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wzVdnyP8ppM"
   },
   "source": [
    "Za dane posłuży nam zbiór Olivetti faces - 400 zdjęć twarzy o różnej mimice (po 10 na każdą z 40 osób). Żeby powiększyć trochę rozmiar zbioru posłużymy się prostą techniką *data augmentation* i dodamy odbicia lustrzane zdjęć. W sumie da nam to 800 punktów danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHafBYCUgvyv"
   },
   "outputs": [],
   "source": [
    "# Załadowanie zbioru danych\n",
    "olivetti = fetch_olivetti_faces(download_if_missing=True, shuffle=True, random_state=1337)\n",
    "X, y = olivetti.images, olivetti.target\n",
    "\n",
    "# Data augmentation - odbicie lustrzane\n",
    "X = np.concatenate([X, X[::-1, :]]).reshape((2 * X.shape[0], 64, 64))\n",
    "y = np.concatenate([y, y])\n",
    "\n",
    "print(\"Wymiary zbioru danych:\", X.shape)\n",
    "plt.imshow(X[np.random.randint(X.shape[0])], cmap='gray')\n",
    "plt.title(\"Losowa twarz ze zbioru\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uU_QE7wQinE8"
   },
   "source": [
    "Do łatwego prototypowania sieci neuronowych użyjemy biblioteki **Keras**. Przy budowaniu płaskich modeli możemy posłuzyć się wartstwami *Flatten* i *Reshape* aby nie musieć za każdym razem ręcznie spłaszczać i kwadracić obrazków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HVK0-cmgyCw"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Activation, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ct7tgNqPiy0I"
   },
   "source": [
    "## 1. Podstawowy autokoder\n",
    "Autokodowanie (eng. *autoencoding*) to proces kompresji danych w którym funkcje kompresji i dekompresji są\n",
    "1. Zależne od danych\n",
    "2. Stratne\n",
    "3. Uczące się automatycznie na danych (nie jest potrzebne ręczne wybieranie cech).\n",
    "\n",
    "W każdym miejscu gdzie używane jest pojęcie *autokoder* obie funkcje implementowane są za pomocą sieci neuronowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbqDt1FAAHbe"
   },
   "source": [
    "### Stworzenie modelu\n",
    "Najprostszym modelem autokodera jest jednowarstwowa sieć z warstwą ukrytą o mniejszym rozmiarze, niż rozmiar wejścia.\n",
    "\n",
    "W tym przykładzie będziemy kodować obrazki o wymiarze 4096 (64 x 64) z użyciem warstwy ukrytej o rozmiarze 100 neuronów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fqar0Fc5iuSV"
   },
   "outputs": [],
   "source": [
    "hidden_size1 = 100\n",
    "model1 = Sequential(layers=[\n",
    "    InputLayer(input_shape=(64, 64)),\n",
    "    Flatten(),\n",
    "    Dense(hidden_size1, activation='sigmoid'),\n",
    "    Dense(4096, activation='sigmoid'),\n",
    "    Reshape(target_shape=(64, 64))\n",
    "])\n",
    "model1.compile(loss='mse', optimizer='adam')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6yTjH9ci_8l"
   },
   "outputs": [],
   "source": [
    "history1 = model1.fit(x=X, y=X, epochs=400, batch_size=80, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "McGfmjY4kBv_"
   },
   "source": [
    "### Krzywa uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hf6lx-qtjd1W"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history1.history['loss'])\n",
    "\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NP-W-gADkJ2H"
   },
   "source": [
    "### Wizualizacja ukrytej reprezentacji autokodera\n",
    "Dla sieci neuronowych łatwo można zwizualizować na co zwracają uwagę neurony pierwszej warstwy ukrytej w danych wejściowych (tu: na które części zdjęcia). \n",
    "\n",
    "Korzystając z faktu, że dla danych wejściowych będących wektorami o długości n:\n",
    "\n",
    "$$w_{(in,h)} \\in M_{n}^{h}, \\quad w_{(h, out)} \\in M_{h}^{n}$$\n",
    "\n",
    "możemy wziąć wagi należące do danego neuronu (jedną kolumnę macierzy wag) i przedstawić ich wartości w postaci obrazka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HfNcTMoAV7i"
   },
   "source": [
    "#### Warstwa kodująca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Af2OkqrDkAVJ"
   },
   "outputs": [],
   "source": [
    "latent = model1.layers[1]\n",
    "hidden = latent.get_weights()[0]\n",
    "print(\"Wymiary macierzy wag:\", hidden.shape)\n",
    "offset = np.random.randint(0, hidden_size1)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "rows, cols = 2, 4\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = cols * i + j\n",
    "        ax = fig.add_subplot(rows, cols, k + 1)\n",
    "        ax.imshow(hidden[:, k + offset].reshape(64, 64), cmap='gray')\n",
    "\n",
    "fig.suptitle('Ukryta reprezentacja kodera', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ur0Kj5O5ksSD"
   },
   "source": [
    "#### Warstwa dekodująca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kppz8YeOkMki"
   },
   "outputs": [],
   "source": [
    "latent = model1.layers[2]\n",
    "hidden = latent.get_weights()[0]\n",
    "print(\"Wymiary macierzy wag:\", hidden.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "rows, cols = 2, 4\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = cols * i + j\n",
    "        ax = fig.add_subplot(rows, cols, k + 1)\n",
    "        ax.imshow(hidden[k + offset, :].reshape(64, 64), cmap='gray')\n",
    "\n",
    "fig.suptitle('Ukryta reprezentacja dekodera', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fU0it7i5k-1Q"
   },
   "source": [
    "#### Ekstrakcja dekodera i kodera\n",
    "Biblioteka **Keras** pozwala na łatwe rozdzielenie naszego modelu na część kodującą i dekodującą. Tworzymy w tym celu nowe modele, podając w konstruktorach listę warstw z już przetrenowanego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TaCo4tKXkvih"
   },
   "outputs": [],
   "source": [
    "encoder1 = Sequential(model1.layers[:2])\n",
    "encoder1.build(input_shape=(None, 64, 64))\n",
    "\n",
    "decoder1 = Sequential(model1.layers[2:])\n",
    "decoder1.build(input_shape=(None, hidden_size1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsLdzNInltFS"
   },
   "source": [
    "#### Przekształcenia autokoderem\n",
    "Zobaczmy jak nasz model poradził sobie z zadaniem kompresji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdVLXJbNlEGg"
   },
   "outputs": [],
   "source": [
    "examples = 5\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "offset = np.random.randint(0, X.shape[0])\n",
    "# oryginały\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, k + 1)\n",
    "    ax.imshow(X[k + offset], cmap='gray')\n",
    "# kodowanie\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, examples + k + 1)\n",
    "    image = encoder1.predict(np.expand_dims(X[k + offset], 0))\n",
    "    ax.imshow(image.reshape(10, 10), cmap='gray')\n",
    "# przekształcenia\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, 2 * examples + k + 1)\n",
    "    image = model1.predict(np.expand_dims(X[k + offset], 0))[0]\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IReUJU47w5-j"
   },
   "source": [
    "## 2. Głęboki autokoder\n",
    "Jak widać, o ile najprostsza architektura autokodera może sobie poradzić np. z MNISTem (*left as an exercise to the reader*), o tyle do kompresji zdjęć twarzy nie jest wystarczająca. Używając większej ilości warstw ukrytych model może nauczyć się bardziej złożonych cech obrazów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnxY6OXwFRUt"
   },
   "source": [
    "### Stworzenie modelu\n",
    "Użyjemy dwóch dodatkowych warstw, po jednej w części kodującej i dekodującej aby zachować symetrię. Tym razem celem będzie utajona reprezentacja o wymiarze 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6zlvE47op4g"
   },
   "outputs": [],
   "source": [
    "hidden_size2 = 20\n",
    "model2 = Sequential(layers=[\n",
    "    InputLayer(input_shape=(64, 64)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(hidden_size2, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(4096, activation='sigmoid'),\n",
    "    Reshape(target_shape=(64, 64))\n",
    "])\n",
    "model2.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4XcdOICxPlW"
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(x=X, y=X, epochs=400, batch_size=80, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zai9kOveF35w"
   },
   "source": [
    "### Krzywa uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJKTbqvfxXj8"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history2.history['loss'])\n",
    "\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgP1WUE7F7Es"
   },
   "source": [
    "### Wizualizacja warstw ukrytych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rITihJ01GG13"
   },
   "source": [
    "#### Pierwsza warstwa kodująca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KK1Pz_0Bxrxx"
   },
   "outputs": [],
   "source": [
    "latent = model2.layers[1]\n",
    "hidden = latent.get_weights()[0]\n",
    "offset = np.random.randint(0, hidden_size2)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "rows, cols = 2, 4\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = cols * i + j\n",
    "        ax = fig.add_subplot(rows, cols, k + 1)\n",
    "        ax.imshow(hidden[:, k + offset].reshape(64, 64), cmap='gray')\n",
    "\n",
    "fig.suptitle('Ukryta reprezentacja głębokiego kodera', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mj6lHNx2GPB1"
   },
   "source": [
    "#### Druga warstwa dekodująca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2PrWJj3xxC_"
   },
   "outputs": [],
   "source": [
    "latent = model2.layers[4]\n",
    "\n",
    "hidden = latent.get_weights()[0]\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "rows, cols = 2, 4\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = cols * i + j\n",
    "        ax = fig.add_subplot(rows, cols, k + 1)\n",
    "        ax.imshow(hidden[k + offset, :].reshape(64, 64), cmap='gray')\n",
    "\n",
    "fig.suptitle('Ukryta reprezentacja głębokiego dekodera', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vXGB17OIQIq"
   },
   "source": [
    "#### Ekstrakcja kodera i dekodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOzAlQTbzV8b"
   },
   "outputs": [],
   "source": [
    "encoder2 = Sequential(model2.layers[:3])\n",
    "encoder2.build(input_shape=(None, 64, 64))\n",
    "\n",
    "decoder2 = Sequential(model2.layers[3:])\n",
    "decoder2.build(input_shape=(None, hidden_size2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AsijYnoITy3"
   },
   "source": [
    "#### Przekształcenia głębokim autokoderem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLWDrTFJzGmY"
   },
   "outputs": [],
   "source": [
    "examples = 5\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "offset = np.random.randint(0, X.shape[0])\n",
    "# oryginały\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, k + 1)\n",
    "    ax.imshow(X[k + offset], cmap='gray')\n",
    "# kodowanie\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, examples + k + 1)\n",
    "    image = encoder2.predict(np.expand_dims(X[k + offset], 0))\n",
    "    ax.imshow(image.reshape(4, 5), cmap='gray')\n",
    "# przekształcenia\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, 2 * examples + k + 1)\n",
    "    ax.imshow(model2.predict(np.expand_dims(X[k + offset], 0))[0], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pC73a1pJIuZ9"
   },
   "source": [
    "#### Generowanie nowych twarzy: podejście 1.\n",
    "Techniki redukcji wymiarowości pozwalające na transformację odwrotną (np. *PCA*, autokodery) mogą być wykorzystywane do generowania nowych, nie widzianych wcześniej danych. Tak jak możemy próbkować $n$-wymiarową przestrzeń powstałą po zastosowaniu *PCA* i transformować wybrane wektory w górę, możemy zrobić podobnie w przypadku autokodera.\n",
    "\n",
    "Zobaczmy do jakich przedziałów należą wartości ukrytych reprezentacji obrazów ze zbioru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXQc3c4EJyia"
   },
   "outputs": [],
   "source": [
    "encodings = encoder2.predict(X)\n",
    "maxes = np.max(encodings, axis=0)\n",
    "\n",
    "plt.bar(x=range(hidden_size2), height=maxes)\n",
    "plt.xlabel('Neurony warstwy utajonej')\n",
    "plt.xticks(range(hidden_size2))\n",
    "plt.ylabel('RELu')\n",
    "plt.title('Maksymalne wartości aktywacji')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7nGOpzZKv25"
   },
   "source": [
    "Nie wszystkie neurony muszą być w ogóle aktywowane. W takim przypadku możemy spróbować jeszcze obniżyć wielkość warstwy ukrytej.\n",
    "\n",
    "Do generowania nowych obserwacji można użyć np. biblioteki *ipywidgets* i suwaków, ale ponieważ Google Collaboratory ich nie obsługuje, wylosujemy po prostu wartości neuronów z przedziału \\[0, max\\] dla każdego i wrzucimy je w dekoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3iBhRB5zi0f"
   },
   "outputs": [],
   "source": [
    "#naive approach\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "rows, cols = 2, 4\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = cols * i + j\n",
    "        ax = fig.add_subplot(rows, cols, k + 1)\n",
    "        ax.imshow(decoder2.predict(np.random.beta(0.5, 0.5, size=(1, hidden_size2)) * maxes * 0.75)[0], cmap='gray')\n",
    "\n",
    "fig.suptitle('Paskudne losowo wygenerowane twarze', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sn54zCRK8KTp"
   },
   "source": [
    "## Zastosowania - redukcja wymiarowości\n",
    "$n$ zdjęć $k$-wymiarowych możemy rozpatrywać jako $n$ punktów w $k$-wymiarowej przestrzeni\n",
    "\n",
    "Weźmy dwie najpopularniejsze techniki redukcji wymiarowości:\n",
    "* PCA (Principle Component Analysis) obracającą układ współrzędnych tak, aby maksymalizować w pierwszej kolejności wariancję pierwszej współrzędnej, następnie wariancję drugiej itd.\n",
    "* T-SNE (T-distributed Stochastic Neighbor Embedding) - starającą się zminimalizować rozbieżność między dwoma rozkładami: podobieństwa punktów danych w przestrzeni wejściowej i podobieństwa punktów po redukcji\n",
    "\n",
    "Autokodery składające się z warstw pełnych i o niewielkiej głębokości często uczą się reprezentacji wewnętrznej danych podobnej do głównych składowych wychwytywanych przez PCA. Kodery o bardziej rozbudowanej strukturze mają szansę nauczyć się ciekawszych rozkładów. \n",
    "\n",
    "Jednym z zastosowań autokoderów jest właśnie wizualizacja danych o wysokiej wymiarowości, zazwyczaj w połączeniu z PCA lub T-SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UVJRS1LPQJ_"
   },
   "source": [
    "#### Porównanie metod redukcji wymiarowości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bq1s0Byt1aaP"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def compare_pca_tsne(encoder, the_shape):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X.reshape(800, 4096), y)\n",
    "    dims = pca.n_components_\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    ax = fig.add_subplot(1, 4, 1)\n",
    "    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=10)\n",
    "    ax.set_xlabel('Pierwsza składowa')\n",
    "    ax.set_ylabel('Druga składowa')\n",
    "    ax.set_title('PCA(X)')\n",
    "    \n",
    "    encodings = encoder.predict(X.reshape(the_shape))\n",
    "    encodings_pca = pca.fit_transform(encodings)\n",
    "\n",
    "    ax = fig.add_subplot(1, 4, 2)\n",
    "    ax.scatter(encodings_pca[:, 0], encodings_pca[:, 1], c=y, cmap='viridis', s=10)\n",
    "    ax.set_xlabel('Pierwsza składowa')\n",
    "    ax.set_ylabel('Druga składowa')\n",
    "    ax.set_title('PCA(AE(X))')\n",
    "\n",
    "    tsne_enc = TSNE(n_components=2).fit_transform(X.reshape((800, 4096)))\n",
    "\n",
    "    ax = fig.add_subplot(1, 4, 3)\n",
    "    ax.scatter(tsne_enc[:, 0], tsne_enc[:, 1], c=y, cmap='viridis', s=10)\n",
    "    ax.set_xlabel('Pierwszy wymiar')\n",
    "    ax.set_ylabel('Drugi wymiar')\n",
    "    ax.set_title('TSNE(X)')\n",
    "\n",
    "    tsne_enc = TSNE(n_components=2).fit_transform(encodings)\n",
    "\n",
    "    ax = fig.add_subplot(1, 4, 4)\n",
    "    ax.scatter(tsne_enc[:, 0], tsne_enc[:, 1], c=y, cmap='viridis', s=10)\n",
    "    ax.set_xlabel('Pierwszy wymiar')\n",
    "    ax.set_ylabel('Drugi wymiar')\n",
    "    ax.set_title('TSNE(AE(X))')\n",
    "    \n",
    "    pca.\n",
    "    \n",
    "    plt.show()\n",
    " \n",
    "\n",
    "compare_pca_tsne(encoder2, (800, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5c4QUaOHOSP"
   },
   "source": [
    "#### Generowanie nowych twarzy: podejście 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2qpjuYB7vZF"
   },
   "outputs": [],
   "source": [
    "def sample_PCA(pca, decoder, hidden_size, **kwargs):\n",
    "    vector = np.zeros(pca.n_components_)\n",
    "    i = 0\n",
    "    for value in kwargs.values():\n",
    "        vector[i] = value\n",
    "        i += 1\n",
    "    \n",
    "    image = decoder.predict(pca.inverse_transform(vector).reshape(1, hidden_size)).reshape((64, 64))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "        \n",
    "def generate_PCA(encoder, decoder, hidden_size):  \n",
    "    dims = 16\n",
    "    pca = PCA(n_components = dims).fit(encoder.predict(X))\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    rows, cols = 2, 4\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            k = cols * i + j\n",
    "            ax = fig.add_subplot(rows, cols, k + 1)\n",
    "            kwargs = dict(zip(['feature_' + str(t) for t in range(dims)], 2 * np.random.normal(size=dims)))\n",
    "            sample_PCA(pca, decoder, hidden_size, **kwargs)\n",
    "    fig.suptitle('Twarze wygenerowane z PCA', fontsize='x-large')\n",
    "    plt.show()\n",
    "\n",
    "X = X.reshape(800, 64, 64)\n",
    "generate_PCA(encoder2, decoder2, hidden_size2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PdZ6ipbswXy"
   },
   "source": [
    "## 3. Konwolucyjny autokoder\n",
    "Oczywiście nikt nie broni zbudować autokodera z warstw konwolucyjnych. Model taki będzie się lepiej sprawował w przypadku danych, w których przestrzenne ustawienie jest istotne (np. obrazy właśnie, czy dźwięk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlP7RMUg87j_"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdXrFQ-dHxGb"
   },
   "source": [
    "#### Stworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvlpjFUbs4KP"
   },
   "outputs": [],
   "source": [
    "hidden_size3 = 32\n",
    "def createConvModel():\n",
    "    model3 = Sequential()\n",
    "\n",
    "    model3.add(InputLayer(input_shape=(64, 64, 1)))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2D(filters=32, kernel_size=3))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2D(filters=64, kernel_size=3))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2D(filters=128, kernel_size=3))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Flatten())\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Dense(hidden_size3))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Dense(4608))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Reshape((6, 6, 128)))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2DTranspose(filters=128, kernel_size=5, strides=2))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2DTranspose(filters=64, kernel_size=3, strides=2))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2DTranspose(filters=32, kernel_size=2, strides=2))\n",
    "    model3.add(Activation(\"relu\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    model3.add(Conv2DTranspose(filters=1, kernel_size=3, strides=1))\n",
    "    model3.add(Activation(\"sigmoid\"))\n",
    "    print(model3.output_shape)\n",
    "\n",
    "    #model3.summary()\n",
    "    model3.compile(loss='mse', optimizer='adam')\n",
    "    return model3\n",
    "\n",
    "model3 = createConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jP4A6s8fs_Qi"
   },
   "outputs": [],
   "source": [
    "X = X.reshape((800, 64, 64, 1))\n",
    "history3 = model3.fit(x=X, y=X, epochs=200, batch_size=80, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg1OV_BBIYhH"
   },
   "source": [
    "#### Krzywa uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HvQtw2xtG5-"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history3.history['loss'])\n",
    "\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HmmRMwwIcbx"
   },
   "source": [
    "#### Ekstrakcja kodera i dekodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXqxqg3UyAua"
   },
   "outputs": [],
   "source": [
    "encoder3 = Sequential(model3.layers[:11])\n",
    "encoder3.build(input_shape=(None, 64, 64, 1))\n",
    "\n",
    "decoder3 = Sequential(model3.layers[11:])\n",
    "decoder3.build(input_shape=(None, hidden_size3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "um-AkyT5T7bk"
   },
   "source": [
    "#### Przekształcenia autokoderem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmQ233ztvCuK"
   },
   "outputs": [],
   "source": [
    "examples = 5\n",
    "offset = np.random.randint(0, X.shape[0] - examples)\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "# oryginały\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, k + 1)\n",
    "    ax.imshow(X[k + offset].reshape(64, 64), cmap='gray')\n",
    "# kodowanie\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, examples + k + 1)\n",
    "    image = encoder3.predict(np.expand_dims(X[k + offset], 0))\n",
    "    ax.imshow(image.reshape(4, 8), cmap='gray')\n",
    "# przekształcenia\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(3, examples, 2 * examples + k + 1)\n",
    "    ax.imshow(model3.predict(X[k + offset].reshape((1, 64, 64, 1))).reshape(64, 64), cmap='gray')\n",
    "\n",
    "fig.suptitle('Przekształcenia autokoderem', fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyxL1V-hPKVi"
   },
   "source": [
    "#### Porównanie metod redukcji wymiarowości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FS36md8Vx0cU"
   },
   "outputs": [],
   "source": [
    "compare_pca_tsne(encoder3, (800, 64, 64, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eo8i9UYCSEI4"
   },
   "source": [
    "#### Generowanie nowych twarzy: podejście 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unHyRp1WysDy"
   },
   "outputs": [],
   "source": [
    "X = X.reshape((800, 64, 64, 1))\n",
    "generate_PCA(encoder3, decoder3, hidden_size3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmgR143TSrUI"
   },
   "source": [
    "Na zbiorze danych zawierającym 800 zdjęć twarzy z frontu trudno uzyskać przekonujące wyniki. Tutaj materiał, który prezentuje tę samą technikę (szum -> PCA -> warstwa ukryta -> dekodowanie), [ale na znacznie większym zbiorze danych](https://youtu.be/4VAkrUNLKSo?t=351)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHgFrRccUEa2"
   },
   "source": [
    "## Zastosowanie: odszumianie\n",
    "Możemy zastosować autokoder przetrenowany na zaszumionych danych wejściowych aby otrzymać model potrafiący odszumiać dane podobne do tych ze zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pfAJeljzNig"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.05\n",
    "X_noisy = X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X.shape)\n",
    "\n",
    "plt.imshow(X_noisy[np.random.randint(X_noisy.shape[0])].reshape((64, 64)), cmap='gray')\n",
    "plt.title(\"Losowa zaszumiona twarz ze zbioru\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2T07vL4ATUMl"
   },
   "source": [
    "#### Stworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQKAXiLiWpsw"
   },
   "outputs": [],
   "source": [
    "model4 = createConvModel()\n",
    "X_noisy = X_noisy.reshape((800, 64, 64, 1))\n",
    "X = X.reshape((800, 64, 64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSmRsdU1XZka"
   },
   "outputs": [],
   "source": [
    "history4 = model4.fit(x=X_noisy, y=X, epochs=100, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8NkiFPSTXTH"
   },
   "source": [
    "#### Krzywa uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXI1pkBxSv3m"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history4.history['loss'])\n",
    "\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NW0SnzJgTyNM"
   },
   "source": [
    "#### Ekstrakcja kodera i dekodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LaQP19UT0TM"
   },
   "outputs": [],
   "source": [
    "encoder4 = Sequential(model4.layers[:11])\n",
    "encoder4.build(input_shape=(None, 64, 64, 1))\n",
    "\n",
    "decoder4 = Sequential(model4.layers[11:])\n",
    "decoder4.build(input_shape=(None, hidden_size3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_vNmnHMTfct"
   },
   "source": [
    "#### Odszumianie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tzd475sGTmRR"
   },
   "outputs": [],
   "source": [
    "examples = 5\n",
    "offset = np.random.randint(0, X.shape[0] - examples)\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "# zaszumione\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(4, examples, k + 1)\n",
    "    ax.imshow(X_noisy[k + offset].reshape(64, 64), cmap='gray')\n",
    "# kodowanie\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(4, examples, examples + k + 1)\n",
    "    image = encoder4.predict(np.expand_dims(X_noisy[k + offset], 0))\n",
    "    ax.imshow(image.reshape(4, 8), cmap='gray')\n",
    "# przekształcenia\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(4, examples, 2 * examples + k + 1)\n",
    "    ax.imshow(model4.predict(X_noisy[k + offset].reshape((1, 64, 64, 1))).reshape(64, 64), cmap='gray')\n",
    "# oryginały\n",
    "for k in range(examples):\n",
    "    ax = fig.add_subplot(4, examples, 3 * examples + k + 1)\n",
    "    ax.imshow(X[k + offset].reshape(64, 64), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iMjoy6Py5a7"
   },
   "source": [
    "Odszumianie nie musi oznaczać tylko eliminacji białego szumu.\n",
    "Inne przykłady:\n",
    "* rozpoznawanie kart z [Magic the Gathering](https://hackernoon.com/a-deep-convolutional-denoising-autoencoder-for-image-classification-26c777d3b88e)\n",
    "* [oczyszczanie obrazów](https://arxiv.org/pdf/1606.08921.pdf)\n",
    "* wypełnianie dziur w obrazach ([image impainting](http://people.eecs.berkeley.edu/~pathak/context_encoder/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQR2AingVXZS"
   },
   "source": [
    "## Wariacyjny autokoder\n",
    "Widzieliśmy jak możemy próbować generować nowe obserwacje próbkując warstwę ukrytą różnych autokoderów. W praktyce jednak takie podejście nie jest stosowane. Modelami generatywnymi w kontekście autokoderów są **autokodery wariacyjne**. Budowa przypomina Przedstawione wcześniej głębokie autokodery, jednak zamiast mapować wejścia na neurony symbolizujące arbitralne liczby, mapujemy na neurony oznaczające parametry pewnego rozkładu prawdopodobieństwa, który potem możemy próbkować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyfez_4HXk5n"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yY-tkPcXFEX"
   },
   "source": [
    "#### Stworzenie modelu\n",
    "\n",
    "Najpierw, utwórzmy część kodującą dane wejściowe do przestrzeni utajonej. Użyjemy w tym celu funkcyjnego API biblioteki **Keras**, pozwalającego na utworzenie niestandardowej konfiguracji warstw sieci (dwie warstwy na tym samym poziomie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaRUlXYoTpHI"
   },
   "outputs": [],
   "source": [
    "hidden_size5 = 512\n",
    "latent_size = 2\n",
    "\n",
    "input_layer = Input(batch_shape=(None, 4096))\n",
    "hidden_layer = Dense(hidden_size5, activation='relu')(input_layer)\n",
    "z_mean = Dense(latent_size)(hidden_layer)\n",
    "z_log_sigma = Dense(latent_size)(hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBbHE6xUXWH3"
   },
   "source": [
    "Używając tych parametrów możemy stworzyć generator podobnych danych z powstałej przestrzeni. Ponieważ nie możemy próbkować naszych rozkładów bezpośrednio (utracilibyśmy różniczkowalność) zastosujemy tzw. \"reparametrizatoin trick\":\n",
    "![alt text](https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-18-at-4.36.34-PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9wTI7NSXc1n"
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# uwaga: \"output_shape\" nie jest konieczny przy używaniu backendu TensorFlow\n",
    "# można też napisać `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_size,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcM5ncZqZs_O"
   },
   "source": [
    "Na koniec przekształcamy próbkowane punkty z powrotem na odtworzone dane wejściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ho7MJz6TX6Ml"
   },
   "outputs": [],
   "source": [
    "decoder_h = Dense(hidden_size5, activation='relu')\n",
    "decoder_mean = Dense(4096, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Adzzhz-4aCp7"
   },
   "source": [
    "Na koniec otrzymujemy 3 modele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DFLnfj7ZJ_G"
   },
   "outputs": [],
   "source": [
    "# autokoder end-to-end\n",
    "vae = Model(input_layer, x_decoded_mean)\n",
    "\n",
    "# koder, z danych wejściowych do przestrzeni utajonej\n",
    "v_encoder = Model(input_layer, z_mean)\n",
    "\n",
    "# generator, z przestrzeni utajonej w odtworzone dane wejściowe\n",
    "decoder_input = Input(shape=(latent_size,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6atD097asux"
   },
   "source": [
    "#### Trening\n",
    "\n",
    "Trenujemy nasz model ze specjalną funkcją błędu: sumą błędu rekonstrukcji oraz dywergencji Kullbacka-Leiblera (KL divergence) (określa rozbieżność między dwoma rozkładami prawdopodobieństwa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IxVxFqCaTH1"
   },
   "outputs": [],
   "source": [
    "from keras.objectives import mse\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    kl_loss /= 800\n",
    "    return xent_loss + kl_loss / 2\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrxyf6X5bbKO"
   },
   "source": [
    "Trenujemy nasz model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-lLYd2EbKMM"
   },
   "outputs": [],
   "source": [
    "X = X.reshape((800, 4096))\n",
    "history5 = vae.fit(x=X, y=X, epochs=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGNNJQFwqMjo"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history5.history['loss'])\n",
    "\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQfiuGt4h_Hb"
   },
   "source": [
    "#### Wizualizacja wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iasHAXN5dmkM"
   },
   "outputs": [],
   "source": [
    "def plot_results(models, data, batch_size=80):\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "\n",
    "    # wykres klas w przestrzeni utajonej\n",
    "    z_mean = encoder.predict(x_test, batch_size=batch_size)\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "    # 15x15 2D macierz twarzy\n",
    "    n = 15\n",
    "    image_size = 64\n",
    "    figure = np.zeros((image_size * n, image_size * n))\n",
    "    # liniowo rozmieszczone koordynaty odpowiadające wykresowi 2D\n",
    "    # klas twarzy w p. utajonej\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(image_size, image_size)\n",
    "            figure[i * image_size: (i + 1) * image_size,\n",
    "                   j * image_size: (j + 1) * image_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = image_size // 2\n",
    "    end_range = n * image_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, image_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "plot_results(models=(v_encoder, generator), data=(X, y), batch_size=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dem3CZPe2gNL"
   },
   "source": [
    "Więcej materiałów na temat *VAE*:\n",
    "* [film na YT](https://youtu.be/9zKuYvjFFS8) opisujący zasadę działania\n",
    "* [ten post](http://kvfrans.com/variational-autoencoders-explained/) (w prostych słowach)\n",
    "* i [ten post](https://www.jeremyjordan.me/variational-autoencoders/) z którego pochodzi obrazek, a temat jest dokładniej wytłumaczony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZyIZEHJglbm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Warsztaty.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
